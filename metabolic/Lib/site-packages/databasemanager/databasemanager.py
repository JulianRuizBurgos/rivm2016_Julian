from loggerwrapper import Logger
from couchdb import *
import pandas as pd
import numpy as np
import json, re
import os
import uuid

DIR_NAME = os.path.dirname(__file__)

class DatabaseManager():

    __logger = None
    __process_name = "Database Manager"
    __couchdb_server = None 

    def __init__(self, username, password, address, logger=None):
        self.__configure_logger(logger)
        self.couchdb_server = self.initialize_couchdb_server(username, password, address)

    def __configure_logger(self, logger=None):
        try:
            if logger != None:
                self.__logger = logger
            else:
                self.__logger = Logger("Database Manager")
        except Exception as e:
            print("{process_name}.configure_logger(): Couldn't configure a logger because: {e}".format(process_name=self.__process_name, e=e))
            raise

    def get_couchdb_server(self):
        return self.__couchdb_server

    def initialize_couchdb_server(self, username, password, address="http://127.0.0.1:5984"):
        try:
            secure_loging_string= "://{username}:{password}@".format(username=username, password=password)
            secure_login_address = re.sub(r""":\/\/""", secure_loging_string, address)
            self.__logger.debug("{process_name}.initialize_couchdb_server(): Accessing server {a} with username {u}".format(process_name=self.__process_name, a=address, u=username))
            server = Server(secure_login_address)
            server.resource.session.disable_ssl_verification()
            
        except Exception as e:
            self.__logger.error("{process_name}.initialize_couchdb_server(): Couldn't connect to server {name} because: {e}".format(process_name=self.__process_name, name=address, e=e))
            raise
        return server

    def create_couchdb_database(self, database_name):
        try:
            database = self.couchdb_server.create(database_name)
        except Exception as e:
            self.__logger.error("{process_name}.create_couchdb_database(): Couldn't create database {name} because: {e}".format(process_name=self.__process_name,
                name=database_name, e=e))
            raise

    def delete_couchdb_database(self, database_name):
        try:
            self.couchdb_server.delete(database_name)
        except Exception as e:
            self.__logger.error("{process_name}.create_couchdb_database(): Couldn't delete database {name} because: {e}".format(process_name=self.__process_name,
                name=database_name, e=e))
            raise

    def __add_element_to_database(self, database_name, element):
        try:
            self.couchdb_server[database_name].save(element)
        except Exception as e:
            self.__logger.error("{process_name}.create_couchdb_database(): Couldn't add element to database {db_name} because: {e}".format(process_name=self.__process_name, db_name=database_name))
            raise

    def populate_database_from_csv(self, path, database_name):
        try:
            self.__logger.debug("{process_name}.populate_database_from_csv():Loading csv file {path} as dataframe".format(process_name=self.__process_name, path= os.path.normpath(path)))
            dataframe =  pd.read_csv(path, header=[0,1])
            for i, columns_old in enumerate(dataframe.columns.levels):
                columns_new = np.where(columns_old.str.contains('Unnamed'), '', columns_old)
                dataframe.rename(columns=dict(zip(columns_old, columns_new)), level=i, inplace=True)
            dataframe.columns = [ ":".join(column) for column in dataframe.columns.to_flat_index()]
            dataframe.columns = dataframe.columns.str.strip(':')
            dataframe_as_json = dataframe.to_json(orient="table")
            parsed_json = json.loads(dataframe_as_json)
            
            non_indicator_fields = ["index", "Data source", "Ecoinvent process OR other names", "Unit", "Reference quantity", ""]
            for row in parsed_json["data"]:
                refactored_row_json = {}
                indicators = []
                for key, value in row.items():
                    if key not in non_indicator_fields:
                        indicator_dict = self.__build_indicator_dict(key, value)
                        indicators.append(indicator_dict)
                    else:
                        refactored_row_json[key] = value

                refactored_row_json["indicators"] = indicators
                refactored_row_json = self.__build_entry_dict_and_update_row(refactored_row_json)

                self.__logger.debug(json.dumps(refactored_row_json, indent=4, sort_keys=True))
                self.__add_element_to_database(database_name, refactored_row_json)

        except Exception as e:
            self.__logger.error("{process_name}.load_csv_as_dataframe(): Couldn't load csv file as dataframe because: {e}".format(process_name=self.__process_name, e=e.message))
            raise

    def __build_indicator_dict(self, key, value):
        indicator_fields = key.split(":")
        indicator = {}
        indicator["id"] = uuid.uuid1().int
        indicator["method"] = indicator_fields[0]
        indicator["category"] = indicator_fields[1]
        indicator["indicator"] = indicator_fields[2]
        indicator["units"] = indicator_fields[3]
        indicator["value"] = value

        return indicator

    def __build_entry_dict_and_update_row(self, row):
        ecoinvent_fields = row["Ecoinvent process OR other names"].split(",")
        ecoinvent_fields = [field.strip() for field in ecoinvent_fields]
                
        entry_dict = {}
        entry_dict["id"] = uuid.uuid1().int
        entry_dict["product_name"] = ecoinvent_fields[0]
        entry_dict["geography"] = ecoinvent_fields[1].strip("[]")
        row["method"] = ecoinvent_fields[2]
        entry_dict["unit"] = row["Unit"]
        row["entry"] = entry_dict
        row.pop("Ecoinvent process OR other names")

        return row
